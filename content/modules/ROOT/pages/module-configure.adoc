= Configure the Hosted Cluster

One of the primary use cases for a hosted control planes deployment is to provide multitenancy for organizations so that individuals and teams can have their own clusters with dedicated resources that cannot be infringed upon by other users. Unlike a standard deployment of OpenShift, the configuration for authentication and authorization will need to be performed on the hosting cluster against the `HostedCluster` object. In this lab we will step through the process of adding an additional user account for us to login with, grant that user the cluster admin role, and then test that login functionality. 

*Goals*

* Configure authentication for a regular user.
* Test the authentication once the cluster is configured.

NOTE: In this section we will make use of the Showroom terminal provided to the right of the lab guide to ssh over to our bastion host to perform some command line actions against our cluster.

[[local-auth]]
== Configure Authentication

=== Gather the Kubeconfig file to interact with the hosted cluster

. Using the Showroom terminal, SSH over to your bastion host at *{bastion_public_hostname}*.
+
* *User:* {bastion_ssh_user_name}
* *Password:* {bastion_ssh_password}
+
image::configure/bastion_login.png[link=self, window=blank, width=100%]

. We are going to use the *hcp* CLI, already installed on the bastion host, to gather the Kubeconfig file from our hosted cluster so we can interact with it via CLI. Copy and paste the following syntax into your console and press Enter.
+
[source,sh,role=execute,subs="attributes"]
----
hcp create kubeconfig --name my-hosted-cluster >> my-hosted-cluster.kube
----
+
image::configure/create_kubeconfig.png[link=self, window=blank, width=100%]

. Use the newly created kubeconfig to check the number of nodes in the hosted cluster node pool to confirm it's working as expected.
+
[source,sh,role=execute,subs="attributes"]
----
oc get nodes --kubeconfig my-hosted-cluster.kube
----
+
image::configure/oc_get_nodes.png[link=self, window=blank, width=100%]

. With the kubeconfig downloaded and confirmed working we can move onto our next steps. Use the *clear* command to clean up the terminal screen.

=== Create User Credentials

. In your terminal copy and paste the following syntax and press the *Enter* key.
+
[source,sh,role=execute,subs="attributes"]
----
htpasswd -c -B -b myuser.htpasswd myuser R3dH4t1!
----
+
image::configure/terminal_create_htpasswd.png[link=self, window=blank, width=100%]

. Use the `cat` command to list the contents of the newly created htpasswd file. Use the syntax below to view the file's contents. It will include our username, and the hashed value of the password we created.
+
[source,sh,role=execute,subs="attributes"]
----
cat myuser.htpasswd
----
+
image::configure/cat_htpasswd.png[link=self, window=blank, width=100%]

. Now we can use this value to create a secret in the cluster, which we will need to be able to log in with our own user account. Copy and paste the following syntax, and press the Enter key.
+
[source,sh,role=execute,subs="attributes"]
----
oc create secret generic htpasswd-mysecret --from-file=htpasswd=myuser.htpasswd -n clusters 
----
+
image::configure/secret_created.png[link=self, window=blank, width=100%]

. With the secret created we can now return to our hosting cluster's OpenShift console and to perform the next steps. 

=== Add User to Cluster

. Starting from the *Overview* page of our hosting cluster, on the left-side menu click on *Home* and then *API Explorer*.
+
image::configure/home_api_explorer.png[link=self, window=blank, width=100%]

. Use the *Filter by kind* box to search for the term *HostedCluster*. It should return two values, click on the one that shows it's version as *v1beta1*.
+
image::configure/api_explore_hostedcluster.png[link=self, window=blank, width=100%]

. This will bring up the HostedCluster Resource details, click on the *Instances* tab to see our *my-hosted-cluster* deployment.
+
image::configure/hostedcluster_resource.png[link=self, window=blank, width=100%]

. Click on the three-dot menu to the right side of our instance, and select *Edit HostedCluster* from the drop-down menu.
+
image::configure/edit_hostedcluster.png[link=self, window=blank, width=100%]

. Browse to the bottom of the *spec* section and paste in the following syntax to add the *htpasswd* secret as an identity provider. Once complete, click the blue *Save* button.
+
[source,yaml,role=execute]
----
  configuration:
    oauth:
      identityProviders:
      - htpasswd:
          fileData:
            name: htpasswd-mysecret
        mappingMethod: claim
        name: htpasswd
        type: HTPasswd
----
+
image::configure/add_auth_hostedcluster.png[link=self, window=blank, width=100%]

. Once saved you will get two messages, that the *my-hosted-cluster* object has been updated, and a message that invites you to click the *Reload* button to see the new version. Do that.
+
image::configure/saved_auth_hostedcluster.png[link=self, window=blank, width=100%]

. Return to your terminal and run the following command to show the Oauth pods that exist in the *clusters-my-hosted-cluster* namespace. The *oauth-openshift* pods should have all recently restarted.
+
[source,sh,role=execute,subs="attributes"]
----
oc get pods -n clusters-my-hosted-cluster | grep oauth
----
+
image::configure/oauth_pods_restart.png[link=self, window=blank, width=100%]

. Returning to the OpenShift console, scroll up and confirm that your yaml snippet has been applied, and then click the *local-cluster* menu at the top of the page and select *All Clusters* from the dropdown to return to the RHACM Cluster list.
+
image::configure/return_all_clusters.png[link=self, window=blank, width=100%]

. From the list of clusters that appear, click on *my-hosted-cluster*. Then scroll down to the *Details* section.
+
image::configure/all_clusters_list.png[link=self, window=blank, width=100%] 

. Do you notice that something is now missing? The credentials for the *kubeadmin* login are now missing since that identity provider has been configured.
+
image::configure/hosted_cluster_creds_missing.png[link=self, window=blank, width=100%]


[[test-auth]]
== Test Authentication

. Click on the *Console URL* link above to launch a new tab where we can test our newly created user account using the username *myuser*, and the password  *R3dH4t1!*. Notice that there is no option to select htpasswd as our Identity Provider as we would expect. Let's attempt to login anyways and see what happens.
+
image::configure/cluster_user_login.png[link=self, window=blank, width=100%]

. When we log in, we find ourselves in the *Developer Perspective* which is the default for accounts created with standard user permissions.
+
image::configure/devel_perspective.png[link=self, window=blank, width=100%]

. Click on the *Skip tour* button to bypass and introduction presented to all new users in OpenShift.
+
image::configure/skip_tour.png[link=self, window=blank, width=100%]

. Over on the left-side menu, click on the *Developer* menu, and select *Administrator* from the drop-down list.
+
image::configure/menu_admin.png[link=self, window=blank, width=100%]

. In the *Administrator* view you will see that we are unable to view practically anything. This is because we didn't grant our new user account any additional authority over cluster operations.
+
image::configure/blank_admin_view.png[link=self, window=blank, width=100%]

. Log out of the console by clicking on *myuser* in the upper right corner and selecting *Log out* from the drop-down menu.
+
image::configure/cluster_log_out.png[link=self, window=blank, width=100%]

. Return to the terminal where we are still logged into the bastion host.

. Using the following syntax, use the *kubeconfig* file we created earlier to add your user to the cluster-admins group.
+
[source,sh,role=execute,subs="attributes"]
----
oc adm policy add-cluster-role-to-user cluster-admin myuser --kubeconfig my-hosted-cluster.kube  
----
+
image::configure/myuser_cluster_admin.png[link=self, window=blank, width=100%]

. Return to the web console for *my-hosted-cluster* and login again.
+
image::configure/cluster_user_login.png[link=self, window=blank, width=100%]

. You now find yourself logged into the cluster as the *myuser* account, and as an administrative user with full rights to manage your personal cluster.
+
image::configure/admin_view_full.png[link=self, window=blank, width=100%]

== Summary

In this section we performed a configuration of the hosted cluster by issuing commands from the console of the hosting cluster, and creating secrets and other resources on the hosting cluster. This shows how OpenShift on OpenShfit clusters using hosted control planes can be easily managed from the hosting cluster after being deployed.

